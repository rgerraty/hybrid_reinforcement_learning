{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Updated Moving MNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rgerraty/hybrid_reinforcement_learning/blob/master/Updated_Moving_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvNCv88IHhZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import imageio\n",
        "import test as test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gy07PsAdjlSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Class that creates random moving MNIST image dataset on the fly (15 time steps x [100 batches x 1 x 64 x 64])\n",
        "class MovingMNIST(object):\n",
        "\n",
        "    def __init__(self, train, data_root, seq_len, num_digits, image_size, deterministic):\n",
        "        path = data_root\n",
        "        self.seq_len = seq_len\n",
        "        self.num_digits = num_digits  \n",
        "        self.image_size = image_size\n",
        "        self.step_length = 0.1\n",
        "        self.digit_size = 32\n",
        "        self.deterministic = deterministic\n",
        "        self.seed_is_set = False # multi threaded loading\n",
        "        self.channels = 1 \n",
        "\n",
        "        self.data = datasets.MNIST(\n",
        "            path,\n",
        "            train=train,\n",
        "            download=True,\n",
        "            transform=transforms.Compose(\n",
        "                [transforms.Resize(self.digit_size),\n",
        "                 transforms.ToTensor()]))\n",
        "\n",
        "        self.N = len(self.data) \n",
        "\n",
        "    def set_seed(self, seed):\n",
        "        if not self.seed_is_set:\n",
        "            self.seed_is_set = True\n",
        "            np.random.seed(seed)\n",
        "          \n",
        "    def __len__(self):\n",
        "        return self.N\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        self.set_seed(index)\n",
        "        image_size = self.image_size\n",
        "        digit_size = self.digit_size\n",
        "        x = np.zeros((self.seq_len,\n",
        "                      image_size, \n",
        "                      image_size, \n",
        "                      self.channels),\n",
        "                    dtype=np.float32)\n",
        "        for n in range(self.num_digits):\n",
        "            idx = np.random.randint(self.N)\n",
        "            digit, _ = self.data[idx]\n",
        "\n",
        "            sx = np.random.randint(image_size-digit_size)\n",
        "            sy = np.random.randint(image_size-digit_size)\n",
        "            dx = np.random.randint(-4, 5)\n",
        "            dy = np.random.randint(-4, 5)\n",
        "            for t in range(self.seq_len):\n",
        "                if sy < 0:\n",
        "                    sy = 0 \n",
        "                    if self.deterministic:\n",
        "                        dy = -dy\n",
        "                    else:\n",
        "                        dy = np.random.randint(1, 5)\n",
        "                        dx = np.random.randint(-4, 5)\n",
        "                elif sy >= image_size-32:\n",
        "                    sy = image_size-32-1\n",
        "                    if self.deterministic:\n",
        "                        dy = -dy\n",
        "                    else:\n",
        "                        dy = np.random.randint(-4, 0)\n",
        "                        dx = np.random.randint(-4, 5)\n",
        "                    \n",
        "                if sx < 0:\n",
        "                    sx = 0 \n",
        "                    if self.deterministic:\n",
        "                        dx = -dx\n",
        "                    else:\n",
        "                        dx = np.random.randint(1, 5)\n",
        "                        dy = np.random.randint(-4, 5)\n",
        "                elif sx >= image_size-32:\n",
        "                    sx = image_size-32-1\n",
        "                    if self.deterministic:\n",
        "                        dx = -dx\n",
        "                    else:\n",
        "                        dx = np.random.randint(-4, 0)\n",
        "                        dy = np.random.randint(-4, 5)\n",
        "\n",
        "                x[t, sy:sy+32, sx:sx+32, 0] += digit.numpy().squeeze()\n",
        "                sy += dy\n",
        "                sx += dx\n",
        "\n",
        "        x[x>1] = 1.\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6-5VUcHjqSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_root = 'data'\n",
        "n_past = 5\n",
        "n_future = 10\n",
        "n_time = n_past + n_future\n",
        "image_width = 64\n",
        "num_digits = 2\n",
        "\n",
        "# Creates two MovingMNIST objects, each representing a train/test dataset\n",
        "def load_dataset():\n",
        "    train_data = MovingMNIST(\n",
        "            train=True,\n",
        "            data_root=data_root,\n",
        "            seq_len=n_time,\n",
        "            image_size=image_width,\n",
        "            deterministic=False,\n",
        "            num_digits=num_digits)\n",
        "    test_data = MovingMNIST(\n",
        "            train=False,\n",
        "            data_root=data_root,\n",
        "            #seq_len=n_eval,\n",
        "            seq_len=n_time,\n",
        "            image_size=image_width,\n",
        "            deterministic=False,\n",
        "            num_digits=num_digits)\n",
        "    return train_data, test_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yT71LdO5sZ6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saves two Moving MNIST dataset objects\n",
        "train_data, test_data = load_dataset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMg3CkjcsYcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_threads = 5\n",
        "batch_size = 100\n",
        "\n",
        "\n",
        "# Creates two DataLoader objects from the Moving MNIST dataset objects\n",
        "train_loader = DataLoader(train_data,\n",
        "                          num_workers=data_threads,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True,\n",
        "                          drop_last=True,\n",
        "                          pin_memory=True)\n",
        "test_loader = DataLoader(test_data,\n",
        "                         num_workers=data_threads,\n",
        "                         batch_size=batch_size,\n",
        "                         shuffle=True,\n",
        "                         drop_last=True,\n",
        "                         pin_memory=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIX_5GO7snsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Used to change data from numpy array to tensor\n",
        "dtype = torch.cuda.FloatTensor\n",
        "\n",
        "# Changes numpy sequence arrays to tensor arrays\n",
        "def sequence_input(seq, dtype):\n",
        "    return [Variable(x.type(dtype)) for x in seq]\n",
        "\n",
        "# Fixes ordering of array by transposing dimensions\n",
        "def normalize_data(dtype, sequence):\n",
        "    sequence.transpose_(0, 1)\n",
        "    sequence.transpose_(3, 4).transpose_(2, 3)\n",
        "    \n",
        "    return sequence_input(sequence, dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP96yyQAsNIQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creates a training batch for each sequence in the training DataLoader\n",
        "def get_training_batch():\n",
        "    while True:\n",
        "        for sequence in train_loader:\n",
        "            batch = normalize_data(dtype, sequence)\n",
        "            yield batch\n",
        "\n",
        "# Creates a testing batch for each sequence in the testing DataLoader\n",
        "def get_testing_batch():\n",
        "    while True:\n",
        "        for sequence in test_loader:\n",
        "            batch = normalize_data(dtype, sequence)\n",
        "            yield batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWwboaNl0dHr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creates two batch generator objects with each output of size 15 x [100,1,64,64]\n",
        "training_batch_generator = get_training_batch()\n",
        "testing_batch_generator = get_testing_batch()\n",
        "# Run cell twice if error text pops up"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GfP2LX9GZESS",
        "colab": {}
      },
      "source": [
        "# Switches to cuda\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohH9Dk0WY7Xx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculates and returns random sample from the distribution of latent parameters z_mu (mean) and z_logsigma (variance)\n",
        "def create_z_sample(z_mu,z_logsigma):\n",
        "    z_sigma = torch.exp(z_logsigma)\n",
        "    eps = torch.randn_like(z_sigma)\n",
        "    z_sample = eps.mul(z_sigma).add_(z_mu)\n",
        "    return z_sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVBCLVXj2STD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Class that creates convolutional recurrent neural network model\n",
        "class VAE(nn.Module):\n",
        "  def __init__(self, enc, dec, rnn):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.enc = enc\n",
        "    self.dec = dec\n",
        "    self.rnn = rnn\n",
        "  \n",
        "  def forward(self, x, hidden):\n",
        "    # Returns latent space output of encoder\n",
        "    z_dim = self.enc(x)\n",
        "        \n",
        "    # Returns outputs of latent space rnn \n",
        "    z_mu, z_logsigma, hidden = self.rnn(z_dim,hidden)\n",
        "    \n",
        "    # Returns predicted sample from predicted distribution\n",
        "    z_pred = create_z_sample(z_mu,z_logsigma)\n",
        "    \n",
        "    # Returns image output of decoder\n",
        "    predicted = self.dec(z_pred)\n",
        "        \n",
        "    return predicted, z_mu, z_logsigma, hidden\n",
        "\n",
        "  # Calls method in rnn that initializes hidden state of rnn and creates new weights\n",
        "  def rnn_hidden(self,batch_size):\n",
        "    return self.rnn.init_hidden(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dgv7c5EK2szg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Class that creates encoder model to transform input into latent space\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self,z_dim):\n",
        "    super().__init__()\n",
        "    self.conv1=nn.Conv2d(1,16,kernel_size=3,stride=1,padding=1,bias=False)\n",
        "    self.bn1=nn.BatchNorm2d(16)\n",
        "    self.conv2=nn.Conv2d(16,32,kernel_size=3,stride=2,padding=1,bias=False)\n",
        "    self.bn2=nn.BatchNorm2d(32)\n",
        "    self.conv3=nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1,bias=False)\n",
        "    self.bn3=nn.BatchNorm2d(64)\n",
        "    self.conv4=nn.Conv2d(64,16,kernel_size=3,stride=2,padding=1,bias=False)\n",
        "    self.bn4=nn.BatchNorm2d(16)\n",
        "    \n",
        "    self.fc1 = nn.Linear(16 * 16 * 16, z_dim)\n",
        "    self.fc_bn1 = nn.BatchNorm1d(z_dim)\n",
        "    \n",
        "    \n",
        "  def forward(self, x):\n",
        "    conv1=nn.functional.relu(self.bn1(self.conv1(x)))\n",
        "    conv2=nn.functional.relu(self.bn2(self.conv2(conv1)))\n",
        "    conv3=nn.functional.relu(self.bn3(self.conv3(conv2)))\n",
        "    conv4=nn.functional.relu(self.bn4(self.conv4(conv3))).view(-1, 16 * 16 * 16)\n",
        "    fc1=nn.functional.relu(self.fc_bn1(self.fc1(conv4)))\n",
        "    # Makes encoder output 3-dimensional so that it can pass through LSTM (now [100x1x10]) \n",
        "    fc1 = fc1.unsqueeze(1) \n",
        "    return fc1\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNy7UDoVF7T2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Class that creates rnn model to predict latent space distribution\n",
        "class RNN(nn.Module):\n",
        "  def __init__(self, z_dim, n_hidden, n_layers=1, drop_prob=0.5, lr=0.001):\n",
        "    super().__init__()\n",
        "    \n",
        "    # Saves input size, which is the same size as the latent space\n",
        "    self.z_dim = z_dim\n",
        "    self.n_hidden = n_hidden\n",
        "    self.n_layers = n_layers\n",
        "    self.drop_prob = drop_prob\n",
        "    self.lr = lr\n",
        "    \n",
        "    # Creates LSTM cell that takes in input size, hidden state features, and sets tensors to put batch_size first)\n",
        "    self.lstm = nn.LSTM(self.z_dim, n_hidden, batch_first=True)\n",
        "\n",
        "    # Creates dropout layer on outputs of LSTM\n",
        "    self.dropout = nn.Dropout(drop_prob)\n",
        "    \n",
        "    # Creates final Linear layers that produce outputs z_mu and z_logsigma from input of size z_dim\n",
        "    self.z_mu = nn.Linear(n_hidden,self.z_dim)\n",
        "    self.z_logsigma = nn.Linear(n_hidden, self.z_dim)\n",
        "\n",
        "    \n",
        "  def forward(self,x,hidden):\n",
        "    # Returns output ([100x1x20]) and hidden state of LSTM taking in input ([100x1x10]) and previous hidden state\n",
        "    z_output, hidden = self.lstm(x, hidden)   \n",
        "    # Returns output of dropout layer\n",
        "    out = self.dropout(z_output) \n",
        "    # Returns output of z_mu Linear layer\n",
        "    z_mu = self.z_mu(out)\n",
        "    # Returns output of z_logsigma Linear layer\n",
        "    z_logsigma = self.z_logsigma(out) \n",
        "    return z_mu, z_logsigma, hidden\n",
        "\n",
        "  \n",
        "  # Initializes hidden state of rnn and creates new weights\n",
        "  def init_hidden(self,batch_size):\n",
        "    weight = next(self.parameters()).data\n",
        "    # 1 x 100 x 20\n",
        "    hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(), weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
        "    return hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84LKtr9EP1Rz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Class that creates decoder model to transform the predicted latent space distribution into a predicted image\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self,z_dim):\n",
        "    super().__init__()\n",
        "    self.fc2=nn.Linear(z_dim,z_dim)\n",
        "    self.fc_bn2=nn.BatchNorm1d(z_dim)\n",
        "    self.fc3=nn.Linear(z_dim,16*16*16) #changed\n",
        "    self.fc_bn3=nn.BatchNorm1d(16*16*16) #changed\n",
        "    self.dconv5=nn.ConvTranspose2d(16,64,kernel_size=3,stride=2,padding=1,output_padding=1,bias=False)\n",
        "    self.bn5=nn.BatchNorm2d(64)\n",
        "    self.dconv6=nn.ConvTranspose2d(64,32,kernel_size=3,stride=1,padding=1,bias=False)\n",
        "    self.bn6=nn.BatchNorm2d(32)\n",
        "    self.dconv7=nn.ConvTranspose2d(32,16,kernel_size=3,stride=2,padding=1,output_padding=1,bias=False)\n",
        "    self.bn7=nn.BatchNorm2d(16)\n",
        "    self.dconv8=nn.ConvTranspose2d(16,1,kernel_size=3,stride=1,padding=1,bias=False)\n",
        "    \n",
        "  def forward(self, z_sample):\n",
        "    # Makes the input 2-dimensional again so that it can pass through the deconvolutional layers (now [100x10]) \n",
        "    z_sample = z_sample.squeeze(1) \n",
        "    fc2=nn.functional.relu(self.fc_bn2(self.fc2(z_sample)))\n",
        "    fc3=nn.functional.relu(self.fc_bn3(self.fc3(fc2))).view(-1, 16, 16 , 16)\n",
        "    dconv5=nn.functional.relu(self.bn5(self.dconv5(fc3)))\n",
        "    dconv6=nn.functional.relu(self.bn6(self.dconv6(dconv5)))\n",
        "    dconv7=nn.functional.relu(self.bn7(self.dconv7(dconv6)))\n",
        "    predicted=self.dconv8(dconv7)\n",
        "        \n",
        "    return predicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpeXz0uWeAkS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Class that creates the loss function that calculates loss of the model\n",
        "class Loss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Loss,self).__init__()\n",
        "    self.recon_loss=nn.MSELoss(reduction=\"sum\")\n",
        "    \n",
        "  def forward(self,recon_x,x,mu,logsigma):\n",
        "    recon_loss=self.recon_loss(recon_x,x)\n",
        "    KLD=-.5 * torch.sum(-1+2*logsigma-mu.pow(2)-(logsigma.exp())**2)\n",
        "    \n",
        "    return recon_loss+KLD\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uM-U2BVTew08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Size of latent space\n",
        "z_dim=10\n",
        "\n",
        "# Initializes three parts of model, as well as the model itself\n",
        "encoder=Encoder(z_dim)\n",
        "decoder=Decoder(z_dim)\n",
        "rnn = RNN(z_dim,20)\n",
        "model=VAE(encoder,decoder,rnn).to(device)\n",
        "\n",
        "# Creates the optimizer and initializes the loss function\n",
        "optimizer=optim.Adam(model.parameters(),lr=1e-3)\n",
        "loss_=Loss()\n",
        "\n",
        "seed = 1\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSDiC-UWbucd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Displays image\n",
        "def show(image):\n",
        "    image = image.cpu()\n",
        "    np_image = image.numpy()\n",
        "    plt.imshow(np.transpose(np_image), interpolation='nearest')      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VC93nmqjrg-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Trains model for each epoch\n",
        "def train(x,epoch,train_size): \n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    # Initializes hidden state\n",
        "    hidden = model.rnn_hidden(batch_size)\n",
        "    model.zero_grad()\n",
        "    optimizer.zero_grad()\n",
        "    # Loops through 15 time steps\n",
        "    for time in range(0,n_time-1):\n",
        "        # Batch at time t (used for training)\n",
        "        data = x[time].to(device)\n",
        "        # Batch at time t+1 (used to calculate reconstruction loss)\n",
        "        target = x[time+1].to(device)\n",
        "        hidden = tuple([each.data for each in hidden])\n",
        "        # Returns outputs of model\n",
        "        recon_batch, mu, logsigma, hidden = model(data,hidden)\n",
        "        # Returns reconstruction loss\n",
        "        loss = loss_(recon_batch, target, mu, logsigma)\n",
        "        # Calculates gradient\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        # Optimizes parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "    train_loss /= train_size\n",
        "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss))\n",
        "    train_losses.append(train_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXJme352EBks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(y,epoch,test_size):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    # Initializes hidden state\n",
        "    hidden = model.rnn_hidden(batch_size)\n",
        "    with torch.no_grad():\n",
        "        # Loops through 15 time steps\n",
        "        for time in range(0,n_time-1):\n",
        "            # Batch at time t (used for testing)\n",
        "            data = y[time].to(device)\n",
        "            # Batch at time t+1 (used to calculate reconstruction loss)\n",
        "            target = y[time+1].to(device)\n",
        "            hidden = tuple([each.data for each in hidden])\n",
        "            # Returns outputs of model\n",
        "            recon_batch, mu, logsigma, hidden = model(data,hidden)\n",
        "            # Returns reconstruction loss\n",
        "            test_loss += loss_(recon_batch, target, mu, logsigma).item()\n",
        "                \n",
        "    test_loss /= test_size\n",
        "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
        "    val_losses.append(test_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_jFHM22tAFL",
        "colab_type": "code",
        "outputId": "048e1555-97b5-478b-c72d-23f32ffd9228",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "num_epochs = 5\n",
        "epoch_size = 50\n",
        "size = (n_time-1)*batch_size\n",
        "\n",
        "# Iterates through the number of epochs\n",
        "for epoch in range(num_epochs):\n",
        "    # Iterates through the steps in an epoch\n",
        "    for step in range(epoch_size):\n",
        "        # Returns a training batch for training \n",
        "        x = next(training_batch_generator)\n",
        "        train(x,epoch,size)\n",
        "        # Returns a testing batch for testing\n",
        "        y = next(testing_batch_generator)\n",
        "        test(y,epoch,size)\n",
        "    \n",
        "    # Finds a sample in the trained latent space and displays the corresponding dream image\n",
        "    with torch.no_grad():\n",
        "        sample_z = torch.randn(100, z_dim).to(device) #64\n",
        "        sample = model.dec(sample_z).cpu()\n",
        "    show(sample[0,0,:,:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====> Epoch: 0 Average loss: 1177.4070\n",
            "====> Test set loss: 217.3529\n",
            "====> Epoch: 0 Average loss: 485.8011\n",
            "====> Test set loss: 301.3097\n",
            "====> Epoch: 0 Average loss: 511.8778\n",
            "====> Test set loss: 424.6139\n",
            "====> Epoch: 0 Average loss: 584.5063\n",
            "====> Test set loss: 428.4787\n",
            "====> Epoch: 0 Average loss: 426.5179\n",
            "====> Test set loss: 414.1768\n",
            "====> Epoch: 0 Average loss: 415.3839\n",
            "====> Test set loss: 267.9256\n",
            "====> Epoch: 0 Average loss: 280.9224\n",
            "====> Test set loss: 308.7571\n",
            "====> Epoch: 0 Average loss: 275.5430\n",
            "====> Test set loss: 243.2179\n",
            "====> Epoch: 0 Average loss: 234.4564\n",
            "====> Test set loss: 243.8062\n",
            "====> Epoch: 0 Average loss: 238.8287\n",
            "====> Test set loss: 223.8885\n",
            "====> Epoch: 0 Average loss: 221.4150\n",
            "====> Test set loss: 230.7930\n",
            "====> Epoch: 0 Average loss: 219.0386\n",
            "====> Test set loss: 206.7495\n",
            "====> Epoch: 0 Average loss: 215.1644\n",
            "====> Test set loss: 200.4909\n",
            "====> Epoch: 0 Average loss: 214.2352\n",
            "====> Test set loss: 205.8838\n",
            "====> Epoch: 0 Average loss: 202.4960\n",
            "====> Test set loss: 215.6873\n",
            "====> Epoch: 0 Average loss: 218.2795\n",
            "====> Test set loss: 199.3413\n",
            "====> Epoch: 0 Average loss: 210.0157\n",
            "====> Test set loss: 211.6198\n",
            "====> Epoch: 0 Average loss: 201.9208\n",
            "====> Test set loss: 210.6986\n",
            "====> Epoch: 0 Average loss: 203.7700\n",
            "====> Test set loss: 197.5267\n",
            "====> Epoch: 0 Average loss: 208.9794\n",
            "====> Test set loss: 193.2667\n",
            "====> Epoch: 0 Average loss: 197.4171\n",
            "====> Test set loss: 213.6275\n",
            "====> Epoch: 0 Average loss: 191.2294\n",
            "====> Test set loss: 206.1299\n",
            "====> Epoch: 0 Average loss: 205.4370\n",
            "====> Test set loss: 190.6205\n",
            "====> Epoch: 0 Average loss: 211.7448\n",
            "====> Test set loss: 192.2426\n",
            "====> Epoch: 0 Average loss: 188.5677\n",
            "====> Test set loss: 189.0025\n",
            "====> Epoch: 0 Average loss: 190.2855\n",
            "====> Test set loss: 183.0718\n",
            "====> Epoch: 0 Average loss: 203.6672\n",
            "====> Test set loss: 187.0376\n",
            "====> Epoch: 0 Average loss: 200.2089\n",
            "====> Test set loss: 201.4493\n",
            "====> Epoch: 0 Average loss: 186.5354\n",
            "====> Test set loss: 204.2550\n",
            "====> Epoch: 0 Average loss: 190.0087\n",
            "====> Test set loss: 189.8784\n",
            "====> Epoch: 0 Average loss: 196.2117\n",
            "====> Test set loss: 183.1567\n",
            "====> Epoch: 0 Average loss: 183.9662\n",
            "====> Test set loss: 192.7528\n",
            "====> Epoch: 0 Average loss: 184.0628\n",
            "====> Test set loss: 184.3922\n",
            "====> Epoch: 0 Average loss: 199.5063\n",
            "====> Test set loss: 170.3799\n",
            "====> Epoch: 0 Average loss: 192.9834\n",
            "====> Test set loss: 190.2013\n",
            "====> Epoch: 0 Average loss: 165.9573\n",
            "====> Test set loss: 187.5866\n",
            "====> Epoch: 0 Average loss: 185.7470\n",
            "====> Test set loss: 168.5195\n",
            "====> Epoch: 0 Average loss: 193.9248\n",
            "====> Test set loss: 178.2563\n",
            "====> Epoch: 0 Average loss: 176.0033\n",
            "====> Test set loss: 177.2871\n",
            "====> Epoch: 0 Average loss: 182.3981\n",
            "====> Test set loss: 165.7111\n",
            "====> Epoch: 0 Average loss: 183.5155\n",
            "====> Test set loss: 174.1968\n",
            "====> Epoch: 0 Average loss: 172.9350\n",
            "====> Test set loss: 172.6045\n",
            "====> Epoch: 0 Average loss: 179.9182\n",
            "====> Test set loss: 161.9087\n",
            "====> Epoch: 0 Average loss: 179.6552\n",
            "====> Test set loss: 169.3864\n",
            "====> Epoch: 0 Average loss: 171.3715\n",
            "====> Test set loss: 173.2233\n",
            "====> Epoch: 0 Average loss: 179.1757\n",
            "====> Test set loss: 156.4982\n",
            "====> Epoch: 0 Average loss: 166.2507\n",
            "====> Test set loss: 165.5152\n",
            "====> Epoch: 0 Average loss: 165.3027\n",
            "====> Test set loss: 162.5119\n",
            "====> Epoch: 0 Average loss: 170.8644\n",
            "====> Test set loss: 160.6740\n",
            "====> Epoch: 0 Average loss: 167.3099\n",
            "====> Test set loss: 162.0189\n",
            "====> Epoch: 1 Average loss: 158.1413\n",
            "====> Test set loss: 164.1152\n",
            "====> Epoch: 1 Average loss: 164.3034\n",
            "====> Test set loss: 157.2944\n",
            "====> Epoch: 1 Average loss: 161.7945\n",
            "====> Test set loss: 156.8006\n",
            "====> Epoch: 1 Average loss: 161.6272\n",
            "====> Test set loss: 156.3526\n",
            "====> Epoch: 1 Average loss: 161.6640\n",
            "====> Test set loss: 160.5957\n",
            "====> Epoch: 1 Average loss: 164.8994\n",
            "====> Test set loss: 151.0639\n",
            "====> Epoch: 1 Average loss: 163.1318\n",
            "====> Test set loss: 159.2446\n",
            "====> Epoch: 1 Average loss: 160.3174\n",
            "====> Test set loss: 159.5288\n",
            "====> Epoch: 1 Average loss: 158.5038\n",
            "====> Test set loss: 166.5926\n",
            "====> Epoch: 1 Average loss: 152.0784\n",
            "====> Test set loss: 147.8486\n",
            "====> Epoch: 1 Average loss: 155.0850\n",
            "====> Test set loss: 151.0779\n",
            "====> Epoch: 1 Average loss: 161.4587\n",
            "====> Test set loss: 162.6520\n",
            "====> Epoch: 1 Average loss: 154.6122\n",
            "====> Test set loss: 148.1109\n",
            "====> Epoch: 1 Average loss: 158.8739\n",
            "====> Test set loss: 156.1364\n",
            "====> Epoch: 1 Average loss: 161.0322\n",
            "====> Test set loss: 155.9394\n",
            "====> Epoch: 1 Average loss: 156.1897\n",
            "====> Test set loss: 161.7325\n",
            "====> Epoch: 1 Average loss: 153.4326\n",
            "====> Test set loss: 156.8945\n",
            "====> Epoch: 1 Average loss: 150.3221\n",
            "====> Test set loss: 155.8368\n",
            "====> Epoch: 1 Average loss: 160.8060\n",
            "====> Test set loss: 155.1816\n",
            "====> Epoch: 1 Average loss: 157.3061\n",
            "====> Test set loss: 154.6093\n",
            "====> Epoch: 1 Average loss: 164.9988\n",
            "====> Test set loss: 153.1502\n",
            "====> Epoch: 1 Average loss: 160.7565\n",
            "====> Test set loss: 154.1405\n",
            "====> Epoch: 1 Average loss: 153.5050\n",
            "====> Test set loss: 160.1444\n",
            "====> Epoch: 1 Average loss: 162.4787\n",
            "====> Test set loss: 151.5888\n",
            "====> Epoch: 1 Average loss: 164.2243\n",
            "====> Test set loss: 153.5235\n",
            "====> Epoch: 1 Average loss: 166.4396\n",
            "====> Test set loss: 165.3839\n",
            "====> Epoch: 1 Average loss: 153.9542\n",
            "====> Test set loss: 154.3048\n",
            "====> Epoch: 1 Average loss: 164.9124\n",
            "====> Test set loss: 155.1513\n",
            "====> Epoch: 1 Average loss: 163.8122\n",
            "====> Test set loss: 155.6621\n",
            "====> Epoch: 1 Average loss: 157.7134\n",
            "====> Test set loss: 156.5955\n",
            "====> Epoch: 1 Average loss: 161.5720\n",
            "====> Test set loss: 161.6531\n",
            "====> Epoch: 1 Average loss: 164.5317\n",
            "====> Test set loss: 158.5201\n",
            "====> Epoch: 1 Average loss: 171.6850\n",
            "====> Test set loss: 152.7334\n",
            "====> Epoch: 1 Average loss: 164.8098\n",
            "====> Test set loss: 168.3121\n",
            "====> Epoch: 1 Average loss: 157.8807\n",
            "====> Test set loss: 162.5311\n",
            "====> Epoch: 1 Average loss: 171.2286\n",
            "====> Test set loss: 155.3138\n",
            "====> Epoch: 1 Average loss: 176.6981\n",
            "====> Test set loss: 159.3997\n",
            "====> Epoch: 1 Average loss: 169.9035\n",
            "====> Test set loss: 170.6329\n",
            "====> Epoch: 1 Average loss: 164.2441\n",
            "====> Test set loss: 162.7859\n",
            "====> Epoch: 1 Average loss: 167.8910\n",
            "====> Test set loss: 155.8197\n",
            "====> Epoch: 1 Average loss: 169.2170\n",
            "====> Test set loss: 165.1305\n",
            "====> Epoch: 1 Average loss: 157.9997\n",
            "====> Test set loss: 161.9748\n",
            "====> Epoch: 1 Average loss: 164.0615\n",
            "====> Test set loss: 156.3590\n",
            "====> Epoch: 1 Average loss: 165.2822\n",
            "====> Test set loss: 158.5594\n",
            "====> Epoch: 1 Average loss: 157.3463\n",
            "====> Test set loss: 175.2880\n",
            "====> Epoch: 1 Average loss: 168.2620\n",
            "====> Test set loss: 152.3918\n",
            "====> Epoch: 1 Average loss: 175.4706\n",
            "====> Test set loss: 159.6931\n",
            "====> Epoch: 1 Average loss: 159.1515\n",
            "====> Test set loss: 176.3721\n",
            "====> Epoch: 1 Average loss: 168.2987\n",
            "====> Test set loss: 158.7232\n",
            "====> Epoch: 1 Average loss: 178.4254\n",
            "====> Test set loss: 158.6692\n",
            "====> Epoch: 2 Average loss: 156.7860\n",
            "====> Test set loss: 173.5927\n",
            "====> Epoch: 2 Average loss: 169.8166\n",
            "====> Test set loss: 155.4104\n",
            "====> Epoch: 2 Average loss: 170.7929\n",
            "====> Test set loss: 159.5289\n",
            "====> Epoch: 2 Average loss: 159.7380\n",
            "====> Test set loss: 174.8885\n",
            "====> Epoch: 2 Average loss: 156.7157\n",
            "====> Test set loss: 150.0289\n",
            "====> Epoch: 2 Average loss: 163.1070\n",
            "====> Test set loss: 157.1098\n",
            "====> Epoch: 2 Average loss: 156.7334\n",
            "====> Test set loss: 166.1624\n",
            "====> Epoch: 2 Average loss: 164.1973\n",
            "====> Test set loss: 151.8961\n",
            "====> Epoch: 2 Average loss: 160.3018\n",
            "====> Test set loss: 157.6945\n",
            "====> Epoch: 2 Average loss: 151.2144\n",
            "====> Test set loss: 158.7162\n",
            "====> Epoch: 2 Average loss: 158.7664\n",
            "====> Test set loss: 150.6864\n",
            "====> Epoch: 2 Average loss: 154.7934\n",
            "====> Test set loss: 154.7087\n",
            "====> Epoch: 2 Average loss: 157.8006\n",
            "====> Test set loss: 164.7205\n",
            "====> Epoch: 2 Average loss: 157.4370\n",
            "====> Test set loss: 159.4817\n",
            "====> Epoch: 2 Average loss: 157.9437\n",
            "====> Test set loss: 151.6313\n",
            "====> Epoch: 2 Average loss: 162.7856\n",
            "====> Test set loss: 156.4859\n",
            "====> Epoch: 2 Average loss: 151.1817\n",
            "====> Test set loss: 160.7031\n",
            "====> Epoch: 2 Average loss: 153.3637\n",
            "====> Test set loss: 150.6588\n",
            "====> Epoch: 2 Average loss: 161.4594\n",
            "====> Test set loss: 151.0490\n",
            "====> Epoch: 2 Average loss: 161.1187\n",
            "====> Test set loss: 153.4703\n",
            "====> Epoch: 2 Average loss: 157.7375\n",
            "====> Test set loss: 160.5856\n",
            "====> Epoch: 2 Average loss: 159.4678\n",
            "====> Test set loss: 155.4192\n",
            "====> Epoch: 2 Average loss: 164.7861\n",
            "====> Test set loss: 151.6107\n",
            "====> Epoch: 2 Average loss: 157.1396\n",
            "====> Test set loss: 160.0946\n",
            "====> Epoch: 2 Average loss: 157.1179\n",
            "====> Test set loss: 157.2841\n",
            "====> Epoch: 2 Average loss: 162.4846\n",
            "====> Test set loss: 155.5341\n",
            "====> Epoch: 2 Average loss: 164.2338\n",
            "====> Test set loss: 163.1546\n",
            "====> Epoch: 2 Average loss: 148.7610\n",
            "====> Test set loss: 156.3431\n",
            "====> Epoch: 2 Average loss: 163.5265\n",
            "====> Test set loss: 151.6366\n",
            "====> Epoch: 2 Average loss: 168.8090\n",
            "====> Test set loss: 156.8432\n",
            "====> Epoch: 2 Average loss: 151.0729\n",
            "====> Test set loss: 167.7285\n",
            "====> Epoch: 2 Average loss: 164.0037\n",
            "====> Test set loss: 152.9414\n",
            "====> Epoch: 2 Average loss: 159.6936\n",
            "====> Test set loss: 157.8764\n",
            "====> Epoch: 2 Average loss: 157.1262\n",
            "====> Test set loss: 158.2236\n",
            "====> Epoch: 2 Average loss: 155.3562\n",
            "====> Test set loss: 153.1737\n",
            "====> Epoch: 2 Average loss: 159.7805\n",
            "====> Test set loss: 153.4314\n",
            "====> Epoch: 2 Average loss: 155.8497\n",
            "====> Test set loss: 154.7511\n",
            "====> Epoch: 2 Average loss: 158.9084\n",
            "====> Test set loss: 148.0088\n",
            "====> Epoch: 2 Average loss: 156.5102\n",
            "====> Test set loss: 155.2984\n",
            "====> Epoch: 2 Average loss: 153.3245\n",
            "====> Test set loss: 150.0804\n",
            "====> Epoch: 2 Average loss: 167.6027\n",
            "====> Test set loss: 150.3775\n",
            "====> Epoch: 2 Average loss: 159.7651\n",
            "====> Test set loss: 159.5536\n",
            "====> Epoch: 2 Average loss: 154.5988\n",
            "====> Test set loss: 152.2576\n",
            "====> Epoch: 2 Average loss: 156.7271\n",
            "====> Test set loss: 151.4965\n",
            "====> Epoch: 2 Average loss: 152.5558\n",
            "====> Test set loss: 149.8655\n",
            "====> Epoch: 2 Average loss: 150.2647\n",
            "====> Test set loss: 150.4606\n",
            "====> Epoch: 2 Average loss: 152.0282\n",
            "====> Test set loss: 149.2096\n",
            "====> Epoch: 2 Average loss: 149.7754\n",
            "====> Test set loss: 149.1925\n",
            "====> Epoch: 2 Average loss: 153.4079\n",
            "====> Test set loss: 147.1880\n",
            "====> Epoch: 2 Average loss: 152.3418\n",
            "====> Test set loss: 152.0793\n",
            "====> Epoch: 3 Average loss: 153.8292\n",
            "====> Test set loss: 149.9839\n",
            "====> Epoch: 3 Average loss: 151.5049\n",
            "====> Test set loss: 145.9831\n",
            "====> Epoch: 3 Average loss: 158.4726\n",
            "====> Test set loss: 149.6436\n",
            "====> Epoch: 3 Average loss: 154.5808\n",
            "====> Test set loss: 149.5059\n",
            "====> Epoch: 3 Average loss: 151.3468\n",
            "====> Test set loss: 155.9454\n",
            "====> Epoch: 3 Average loss: 150.8602\n",
            "====> Test set loss: 147.5622\n",
            "====> Epoch: 3 Average loss: 157.5887\n",
            "====> Test set loss: 151.8789\n",
            "====> Epoch: 3 Average loss: 156.2424\n",
            "====> Test set loss: 151.0047\n",
            "====> Epoch: 3 Average loss: 149.6732\n",
            "====> Test set loss: 160.0840\n",
            "====> Epoch: 3 Average loss: 148.1554\n",
            "====> Test set loss: 145.8959\n",
            "====> Epoch: 3 Average loss: 151.5957\n",
            "====> Test set loss: 148.1002\n",
            "====> Epoch: 3 Average loss: 151.9499\n",
            "====> Test set loss: 149.4419\n",
            "====> Epoch: 3 Average loss: 152.1743\n",
            "====> Test set loss: 143.7831\n",
            "====> Epoch: 3 Average loss: 151.4233\n",
            "====> Test set loss: 150.7771\n",
            "====> Epoch: 3 Average loss: 150.8875\n",
            "====> Test set loss: 152.9074\n",
            "====> Epoch: 3 Average loss: 153.4741\n",
            "====> Test set loss: 148.8162\n",
            "====> Epoch: 3 Average loss: 144.8539\n",
            "====> Test set loss: 156.6168\n",
            "====> Epoch: 3 Average loss: 152.4822\n",
            "====> Test set loss: 149.3380\n",
            "====> Epoch: 3 Average loss: 154.6255\n",
            "====> Test set loss: 150.5007\n",
            "====> Epoch: 3 Average loss: 150.7204\n",
            "====> Test set loss: 153.3476\n",
            "====> Epoch: 3 Average loss: 158.1218\n",
            "====> Test set loss: 148.6667\n",
            "====> Epoch: 3 Average loss: 155.3902\n",
            "====> Test set loss: 151.2975\n",
            "====> Epoch: 3 Average loss: 152.2652\n",
            "====> Test set loss: 157.4839\n",
            "====> Epoch: 3 Average loss: 154.5523\n",
            "====> Test set loss: 146.3738\n",
            "====> Epoch: 3 Average loss: 151.9372\n",
            "====> Test set loss: 145.1737\n",
            "====> Epoch: 3 Average loss: 148.0522\n",
            "====> Test set loss: 155.0413\n",
            "====> Epoch: 3 Average loss: 155.6258\n",
            "====> Test set loss: 151.6194\n",
            "====> Epoch: 3 Average loss: 156.9014\n",
            "====> Test set loss: 151.1112\n",
            "====> Epoch: 3 Average loss: 163.4021\n",
            "====> Test set loss: 149.4023\n",
            "====> Epoch: 3 Average loss: 156.8332\n",
            "====> Test set loss: 154.2478\n",
            "====> Epoch: 3 Average loss: 156.1532\n",
            "====> Test set loss: 152.6397\n",
            "====> Epoch: 3 Average loss: 160.0159\n",
            "====> Test set loss: 162.1631\n",
            "====> Epoch: 3 Average loss: 151.4242\n",
            "====> Test set loss: 148.1562\n",
            "====> Epoch: 3 Average loss: 154.2466\n",
            "====> Test set loss: 155.2860\n",
            "====> Epoch: 3 Average loss: 157.1078\n",
            "====> Test set loss: 160.7486\n",
            "====> Epoch: 3 Average loss: 159.9406\n",
            "====> Test set loss: 159.4296\n",
            "====> Epoch: 3 Average loss: 158.6542\n",
            "====> Test set loss: 144.1927\n",
            "====> Epoch: 3 Average loss: 164.4465\n",
            "====> Test set loss: 159.1086\n",
            "====> Epoch: 3 Average loss: 155.9986\n",
            "====> Test set loss: 159.7687\n",
            "====> Epoch: 3 Average loss: 158.6338\n",
            "====> Test set loss: 151.5876\n",
            "====> Epoch: 3 Average loss: 151.3601\n",
            "====> Test set loss: 159.9507\n",
            "====> Epoch: 3 Average loss: 159.4891\n",
            "====> Test set loss: 153.8028\n",
            "====> Epoch: 3 Average loss: 158.0511\n",
            "====> Test set loss: 153.7899\n",
            "====> Epoch: 3 Average loss: 154.2125\n",
            "====> Test set loss: 152.6819\n",
            "====> Epoch: 3 Average loss: 151.9970\n",
            "====> Test set loss: 155.5615\n",
            "====> Epoch: 3 Average loss: 147.6107\n",
            "====> Test set loss: 150.1804\n",
            "====> Epoch: 3 Average loss: 155.6385\n",
            "====> Test set loss: 149.1287\n",
            "====> Epoch: 3 Average loss: 154.7650\n",
            "====> Test set loss: 146.1485\n",
            "====> Epoch: 3 Average loss: 148.1933\n",
            "====> Test set loss: 153.4131\n",
            "====> Epoch: 3 Average loss: 153.3597\n",
            "====> Test set loss: 151.8900\n",
            "====> Epoch: 4 Average loss: 157.3187\n",
            "====> Test set loss: 152.6411\n",
            "====> Epoch: 4 Average loss: 149.3319\n",
            "====> Test set loss: 150.4782\n",
            "====> Epoch: 4 Average loss: 143.5449\n",
            "====> Test set loss: 150.6049\n",
            "====> Epoch: 4 Average loss: 153.3729\n",
            "====> Test set loss: 147.8293\n",
            "====> Epoch: 4 Average loss: 157.2279\n",
            "====> Test set loss: 148.6289\n",
            "====> Epoch: 4 Average loss: 149.3187\n",
            "====> Test set loss: 143.0960\n",
            "====> Epoch: 4 Average loss: 151.2951\n",
            "====> Test set loss: 147.3826\n",
            "====> Epoch: 4 Average loss: 151.8162\n",
            "====> Test set loss: 154.9148\n",
            "====> Epoch: 4 Average loss: 148.9623\n",
            "====> Test set loss: 148.5369\n",
            "====> Epoch: 4 Average loss: 153.5170\n",
            "====> Test set loss: 144.7334\n",
            "====> Epoch: 4 Average loss: 157.5498\n",
            "====> Test set loss: 147.8661\n",
            "====> Epoch: 4 Average loss: 153.7526\n",
            "====> Test set loss: 149.8094\n",
            "====> Epoch: 4 Average loss: 156.1364\n",
            "====> Test set loss: 149.3866\n",
            "====> Epoch: 4 Average loss: 153.5672\n",
            "====> Test set loss: 147.4521\n",
            "====> Epoch: 4 Average loss: 150.9812\n",
            "====> Test set loss: 153.6475\n",
            "====> Epoch: 4 Average loss: 150.2792\n",
            "====> Test set loss: 148.2630\n",
            "====> Epoch: 4 Average loss: 153.8793\n",
            "====> Test set loss: 149.4026\n",
            "====> Epoch: 4 Average loss: 153.9575\n",
            "====> Test set loss: 148.4013\n",
            "====> Epoch: 4 Average loss: 149.8481\n",
            "====> Test set loss: 151.6229\n",
            "====> Epoch: 4 Average loss: 152.0749\n",
            "====> Test set loss: 158.4089\n",
            "====> Epoch: 4 Average loss: 153.4334\n",
            "====> Test set loss: 149.4185\n",
            "====> Epoch: 4 Average loss: 146.4696\n",
            "====> Test set loss: 149.7156\n",
            "====> Epoch: 4 Average loss: 155.4474\n",
            "====> Test set loss: 148.1997\n",
            "====> Epoch: 4 Average loss: 152.3903\n",
            "====> Test set loss: 146.1461\n",
            "====> Epoch: 4 Average loss: 144.4161\n",
            "====> Test set loss: 150.7628\n",
            "====> Epoch: 4 Average loss: 157.0725\n",
            "====> Test set loss: 150.6116\n",
            "====> Epoch: 4 Average loss: 151.0076\n",
            "====> Test set loss: 150.1968\n",
            "====> Epoch: 4 Average loss: 148.5125\n",
            "====> Test set loss: 151.6651\n",
            "====> Epoch: 4 Average loss: 151.3603\n",
            "====> Test set loss: 156.3027\n",
            "====> Epoch: 4 Average loss: 162.1845\n",
            "====> Test set loss: 147.3185\n",
            "====> Epoch: 4 Average loss: 157.6923\n",
            "====> Test set loss: 153.1366\n",
            "====> Epoch: 4 Average loss: 152.1310\n",
            "====> Test set loss: 151.2073\n",
            "====> Epoch: 4 Average loss: 154.6869\n",
            "====> Test set loss: 152.1427\n",
            "====> Epoch: 4 Average loss: 154.1761\n",
            "====> Test set loss: 148.4892\n",
            "====> Epoch: 4 Average loss: 153.9108\n",
            "====> Test set loss: 153.0849\n",
            "====> Epoch: 4 Average loss: 159.2383\n",
            "====> Test set loss: 150.6666\n",
            "====> Epoch: 4 Average loss: 150.1485\n",
            "====> Test set loss: 149.4785\n",
            "====> Epoch: 4 Average loss: 153.7202\n",
            "====> Test set loss: 155.9847\n",
            "====> Epoch: 4 Average loss: 151.2887\n",
            "====> Test set loss: 148.4753\n",
            "====> Epoch: 4 Average loss: 152.8614\n",
            "====> Test set loss: 153.8054\n",
            "====> Epoch: 4 Average loss: 153.1053\n",
            "====> Test set loss: 149.3906\n",
            "====> Epoch: 4 Average loss: 154.8356\n",
            "====> Test set loss: 149.2681\n",
            "====> Epoch: 4 Average loss: 151.5335\n",
            "====> Test set loss: 151.3798\n",
            "====> Epoch: 4 Average loss: 150.3242\n",
            "====> Test set loss: 155.7374\n",
            "====> Epoch: 4 Average loss: 151.0198\n",
            "====> Test set loss: 149.8226\n",
            "====> Epoch: 4 Average loss: 148.6413\n",
            "====> Test set loss: 149.4654\n",
            "====> Epoch: 4 Average loss: 147.3266\n",
            "====> Test set loss: 151.6417\n",
            "====> Epoch: 4 Average loss: 148.2883\n",
            "====> Test set loss: 161.1195\n",
            "====> Epoch: 4 Average loss: 153.5226\n",
            "====> Test set loss: 148.6886\n",
            "====> Epoch: 4 Average loss: 150.6687\n",
            "====> Test set loss: 151.3947\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/zBUquSnVBXiAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k49ZyoqmnMy",
        "colab_type": "code",
        "outputId": "101b1313-4d4b-4fb1-ce62-6566471ea8f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "plt.plot(train_losses,label=\"Training Loss\")\n",
        "plt.plot(val_losses,label=\"Validation Loss\")\n",
        "plt.title(\"Reconstruction Loss: Training vs Validation\")\n",
        "plt.xlabel(\"Number of steps\")\n",
        "plt.ylabel(\"Calculated Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm4AAAFNCAYAAAC5eOMWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJc8PNtuvC4cAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogVs7ujveRFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Returns an image over 15 time steps from 100 possible images in the batch\n",
        "def make_data(input,batch_num):\n",
        "    data = []\n",
        "    for i in range(len(input)):\n",
        "        image = input[i][batch_num,0,:,:]\n",
        "        image = expand_dims(image)\n",
        "        data.append(image)\n",
        "    return data\n",
        "\n",
        "# Adds two dimensions to the image to make it 4D [1x1x64x64]\n",
        "def expand_dims(image):\n",
        "    image = image[None, None, :, :]\n",
        "    return image\n",
        "\n",
        "# Removes two dimensions of the image to make it 2D [64x64]\n",
        "def reduce_dims(image):\n",
        "    image = image.view(64,-1)\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvJKsl725vvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creates new images that predict how image will change over time steps\n",
        "def predict_image(data, hidden):\n",
        "    image_over_time = []\n",
        "    with torch.no_grad():\n",
        "        for time in range(0,len(data)):\n",
        "            image = data[time].to(device)\n",
        "            hidden = tuple([each.data for each in hidden])\n",
        "            recon_image, _, _, hidden = model(image,hidden)\n",
        "            recon_image = reduce_dims(recon_image)\n",
        "            image_over_time.append(recon_image)\n",
        "    return image_over_time, hidden\n",
        "      \n",
        "    \n",
        "# Inputs data to predict how Moving MNINST changes\n",
        "def predict_MMNIST():\n",
        "    pred_set = next(testing_batch_generator)\n",
        "    original_images = make_data(pred_set,0)\n",
        "    image_over_time, hidden = predict_image(original_images[0:n_time-1], model.rnn_hidden(1))\n",
        "    # returns predicted and original images\n",
        "    return image_over_time, original_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQW3IRXEQTFL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creates gif out of set of images over time\n",
        "def create_gif(images,name):\n",
        "    gif = []\n",
        "    for image in images:\n",
        "        image = reduce_dims(image)\n",
        "        image = image.cpu().numpy()\n",
        "        gif.append(image)\n",
        "    imageio.mimsave('/content/{}.gif'.format(name), gif)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bafAqevQ3Gj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted, original = predict_MMNIST()\n",
        "\n",
        "create_gif(predicted,'Predicted')\n",
        "create_gif(original,'Original')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xLjRQYod7_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download MovingMNIST gif for viewing\n",
        "from google.colab import files\n",
        "files.download('Original.gif')\n",
        "files.download('Predicted.gif')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Myy7YhCJQM_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use to check gif locally in colab\n",
        "!ls /content\n",
        "\n",
        "from PIL import Image\n",
        "image = Image.open('Predicted.gif')\n",
        "\n",
        "image"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}